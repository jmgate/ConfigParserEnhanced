# environment-specs.ini
#
#------------------------------------------------------------------------------
#
# This is a configuration file for the `LoadEnv` tool, allowing you to specify
# what is necessary to create each of your environments.  Environments are
# grouped by system (see `supported-systems.ini`).  The syntax for a section
# specifying an environment is as follows:
#
#   [environment-name]
#   # list
#   # of
#   # commands
#
# The `environment-name` can be any string.  The recommended convention is to
# use `<system-name>-<compiler>-<compiler-version>-<mpi>-<mpi-version>-
# <node-type>`, where `<node-type>` is either `serial` or `openmp` and is not
# applicable to CUDA environments.  These names (excepting the `<system-name>-`
# prefix) must match what appears in `supported-envs.ini` for the given system.
#
# The commands that can be used within a section to establish an environment
# are the following:
#
#   * `use section_name`:  Inserts the contents of the section_name section in
#     place of this statement.
#   * `envvar-set envvar : value`:  Sets (or overwrites) an environment
#     variable.
#   * `envvar-append envvar : value`:  Append a value to an existing
#     environment variable.
#   * `envvar-prepend envvar : value`:  Prepend a value to an existing
#     environment variable.
#   * `envvar-remove envvar`:  Removes all occurrences of `envvar` from the
#     list of actions to be applied.
#   * `envvar-unset envvar`:  Unsets (removes) an environment variable, if it
#     exists.
#   * `envvar-remove-substr`:  Removes all occurrences of `substr` from
#     `envvar`.
#   * `envvar-remove-path-entry`:  Removes occurrences of a `path` from a path
#     `envvar`.
#   * `envvar-find-in-path`:  Locate an executable in your path and store the
#     location in the `envvar`.
#   * `envvar-assert-not-empty`:  Throw an error if the `envvar` is not set or
#     is empty.
#   * `module-load module_name : version`:  Load a module.
#   * `module-purge`:  Purge all loaded modules.
#   * `module-remove module_name`:  Removes all uses of `module_name` from the
#     list of actions to be applied.
#   * `module-swap module_old : module_new/nersion`:  Swaps two modules.
#   * `module-unload module_name`:  Unloads a module.
#   * `module-use path`:  Adds a path to modulefiles.
#
# It is possible to create sections within the file that do not correspond to a
# complete environment, but rather are intended to be `use`d within other
# environments.  In such cases, the recommended convention for the section name
# is to use ALL-CAPS, and pick something representative of where it will be
# used, e.g., use `[machine-type-4]` to collect operations that are common to all
# `[machine-type-4_*]` environments.
#
# Note:
#   The operations in a section will be executed in the order in which they
#   appear, so you need to be careful with the ordering of `use` statements and
#   loading metamodules.
#
#------------------------------------------------------------------------------
#
# Modifying an Existing Environment
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#
# To make modifications to an existing environment, the process is:
#
#   1. Find the environment you need to modify within the file.
#   2. Modify the list of commands under that `[environment-name]` section
#      heading (see the command list above) to modify the environment
#      appropriately:
#      * Change environment variables.
#      * Change modules loaded.
#
# Note:
#   It is not recommended that you change the versions of the compiler or MPI
#   implementation for an existing environment.  Instead see below to add a new
#   environment.
#
# Note:
#   If you need to modify multiple environments on a system in the exact same
#   way, there should be a `[SYSTEM-NAME]` section that gets `use`d in the
#   individual environments themselves.  Modify that section instead.  If that
#   section does not yet exist, see the note below under adding a new
#   environment.
#
#------------------------------------------------------------------------------
#
# Adding a New Environment to an Existing System
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#
# To stand up a new environment on a currently supported system, the process
# is:
#
#   1. Find the system to which you would like to add the new environment.
#   2. Determine a new environment name (see above for the naming convention).
#   3. Add a new `[environment-name]` section heading under the given system.
#      Environment names are organized alphabetically for any given system.
#   4. Create a list of commands under that `[environment-name]` section
#      heading (see the command list above) to establish the environment
#      appropriately:
#      * Set/alter environment variables.
#      * Load modules.
#
# Note:
#   If there are any commonalities shared by multiple environments on a certain
#   system:
#   1. Create a `[SYSTEM-NAME]` section to collect the common operations.
#   2. Remove the common operations from the environments from which they were
#      taken.
#   3. Insert a `use SYSTEM-NAME` statement in each of the environments from
#      which commonalities were removed.
#
#------------------------------------------------------------------------------
#
# Removing an Environment
# ~~~~~~~~~~~~~~~~~~~~~~~
#
# When a particular environment is no longer needed---for instance, if a new
# environment was stood up to replace it and it's been sufficiently
# vetted---the process to remove an environment is:
#
#   1. Find the environment you wish to remove in the file.
#   2. Remove the `[environment-name]` section heading and any commands listed
#      underneath it.
#
#------------------------------------------------------------------------------
#
# Adding a New Environment for a New System
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#
# When standing up a completely new system, the procedure is:
#
#   1. Add the new system to `supported-systems.ini`.
#   2. Add the environment to be supported on that system to
#      `supported-envs.ini`.
#   3. Create a new system comment block in the file by copying and pasting an
#      existing one and modifying the system name.  The systems are organized
#      alphabetically within the file.
#   4. Create one or more new environments for the new system.  See above for
#      how to add a new environment.
#
#------------------------------------------------------------------------------



#------------------------------------------------------------------------------
# Common environment options not specific to a particular system.
#------------------------------------------------------------------------------

[COMPILER-VARS]
envvar-set CC  : mpicc
envvar-set CXX : mpicxx
envvar-set FC  : mpif77
envvar-set F90 : mpif90

[MODULE-PURGE]
module-purge

[MPI-COMPILER-VARS]
envvar-find-in-path MPICC  : mpicc
envvar-find-in-path MPICXX : mpicxx
envvar-find-in-path MPIF90 : mpif90

[OMPI-CLANG-VARS]
envvar-find-in-path OMPI_CXX : clang++
envvar-find-in-path OMPI_CC  : clang
envvar-find-in-path OMPI_FC  : gfortran

[OMPI-GNU-VARS]
envvar-find-in-path OMPI_CXX : g++
envvar-find-in-path OMPI_CC  : gcc
envvar-find-in-path OMPI_FC  : gfortran

[OMPI-INTEL-VARS]
envvar-find-in-path OMPI_CXX : icpc
envvar-find-in-path OMPI_CC  : icc
envvar-find-in-path OMPI_FC  : ifort



#------------------------------------------------------------------------------
# machine-type-5
#------------------------------------------------------------------------------

# Partial environments intended to be `use`d within others.

[machine-type-5_PRE]
use MODULE-PURGE

[machine-type-5_POST]
envvar-prepend      PATH          : /projects/netpub/atdm/ninja-1.8.2/bin
envvar-set          LDFLAGS A     : -L/opt/gcc/8.3.0/snos/lib/gcc/x86_64-suse-linux/8.3.0/ -lpthread ${LDFLAGS}
envvar-set          LDFLAGS B     : -L${MPI_ROOT}/lib -lmpich -lrt ${ATP_INSTALL_DIR}/lib/libAtpSigHandler.a ${ATP_INSTALL_DIR}/lib/libbreakpad_client_nostdlib.a ${LDFLAGS}
envvar-find-in-path MPICXX        : CC
envvar-find-in-path MPICC         : cc
envvar-find-in-path MPIF90        : ftn
envvar-set          CXX           : ${MPICXX}
envvar-set          CC            : ${MPICC}
envvar-set          F77           : ${MPIF90}
envvar-set          FC            : ${MPIF90}
envvar-set          F90           : ${MPIF90}
envvar-set          BINUTILS_ROOT : /usr

# Full environments intended to be loaded.

[machine-type-5_intel-19.0.4-mpich-7.7.15-hsw-openmp]
use machine-type-5_PRE
module-load  sparc-dev       : intel-19.0.4_mpich-7.7.15_hsw
envvar-set   OMP_NUM_THREADS : 2
envvar-unset OMP_PLACES
use machine-type-5_POST

[machine-type-5_intel-19.0.4-mpich-7.7.15-knl-openmp]
use machine-type-5_PRE
module-load  sparc-dev            : intel-19.0.4_mpich-7.7.15_knl
envvar-set   SLURM_TASKS_PER_NODE : 16
envvar-set   OMP_NUM_THREADS      : 8
envvar-unset OMP_PLACES
envvar-unset OMP_PROC_BIND
use machine-type-5_POST



#------------------------------------------------------------------------------
# machine-type-4
#------------------------------------------------------------------------------

# Partial environments intended to be `use`d within others.

[machine-type-4_PRE]
use MODULE-PURGE

[machine-type-4_POST]
module-load    cmake           : 3.18.0
module-load    git             : 2.20.0
envvar-prepend PATH            : /projects/atdm_devops/machine-name-3/ninja-fortran-1.8.2
envvar-set     BINUTILS_ROOT   : /usr/tce/packages/gcc/gcc-7.3.1
envvar-prepend LD_LIBRARY_PATH : ${BINUTILS_ROOT}/lib
envvar-set     LIBRARY_PATH    : ${BINUTILS_ROOT}/lib
envvar-prepend INCLUDE         : ${BINUTILS_ROOT}/include
envvar-prepend CPATH           : ${BINUTILS_ROOT}/include
use MPI-COMPILER-VARS

[machine-type-4_CUDA]
envvar-set KOKKOS_NUM_DEVICES : 4

[machine-type-4_GNU]
envvar-prepend LIBRARY_PATH : ${CBLAS_ROOT}/lib

[machine-type-4_OPENMP]
envvar-set OMP_NUM_THREADS : 2

[machine-type-4_XL]
envvar-set BLAS_ROOT      : ${CBLAS_ROOT}
envvar-set XLC_USR_CONFIG : /opt/ibm/xlC/16.1.1/etc/xlc.cfg.rhel.7.6.gcc.7.3.1.cuda.10.1.243
envvar-set XLF_USR_CONFIG : /opt/ibm/xlf/16.1.1/etc/xlf.cfg.rhel.7.5.gcc.7.3.1.cuda.10.1.243

[machine-type-4_GNU-7.3.1-SPMPI-ROLLING]
use machine-type-4_PRE
module-load sparc-dev : gcc-7.3.1_spmpi-rolling
use machine-type-4_POST
use machine-type-4_GNU

[machine-type-4_XL-2020.03.18-SPMPI-ROLLING]
use machine-type-4_PRE
module-load sparc-dev : xl-2020.03.18_spmpi-rolling
use machine-type-4_POST
use machine-type-4_XL

# Full environments intended to be loaded.

[machine-type-4_cuda-10.1.243-gnu-7.3.1-spmpi-rolling]
use machine-type-4_PRE
module-load sparc-dev : cuda-10.1.243_gcc-7.3.1_spmpi-rolling
use machine-type-4_POST
use machine-type-4_CUDA
use machine-type-4_GNU

[machine-type-4_cuda-10.1.243-xl-2020.03.18-spmpi-rolling]
use machine-type-4_PRE
module-load sparc-dev : cuda-10.1.243_xl-2020.03.18_spmpi-rolling
use machine-type-4_POST
use machine-type-4_CUDA
use machine-type-4_XL

[machine-type-4_gnu-7.3.1-spmpi-rolling-openmp]
use machine-type-4_GNU-7.3.1-SPMPI-ROLLING
use machine-type-4_OPENMP

[machine-type-4_gnu-7.3.1-spmpi-rolling-serial]
use machine-type-4_GNU-7.3.1-SPMPI-ROLLING

[machine-type-4_xl-2020.03.18-spmpi-rolling-openmp]
use machine-type-4_XL-2020.03.18-SPMPI-ROLLING
use machine-type-4_OPENMP

[machine-type-4_xl-2020.03.18-spmpi-rolling-serial]
use machine-type-4_XL-2020.03.18-SPMPI-ROLLING



#------------------------------------------------------------------------------
# blake
#------------------------------------------------------------------------------

# Partial environments intended to be `use`d within others.

[BLAKE_PRE]
use MODULE-PURGE

[BLAKE_POST]
envvar-find-in-path OMPI_CXX : icpx
envvar-find-in-path OMPI_CC  : icx
envvar-find-in-path OMPI_FC  : ifx
use MPI-COMPILER-VARS
use COMPILER-VARS

[BLAKE_OPENMP]
envvar-set OMP_NUM_THREADS : 2

[BLAKE_ONEAPI-2021.2.0-OPENMPI-4.0.5]
use BLAKE_PRE
module-load devpack : 20210420/openmpi/4.0.5/intel/oneapi/2021.2.0
use BLAKE_POST

[BLAKE_ONEAPI-2021.1.1-OPENMPI-4.0.5]
use BLAKE_PRE
module-load devpack : 20210310/openmpi/4.0.5/intel/oneapi/2021.1.1
use BLAKE_POST

# Full environments intended to be loaded.

[blake_oneapi-2021.2.0-openmpi-4.0.5-openmp]
use BLAKE_ONEAPI-2021.2.0-OPENMPI-4.0.5
use BLAKE_OPENMP

[blake_oneapi-2021.2.0-openmpi-4.0.5-serial]
use BLAKE_ONEAPI-2021.2.0-OPENMPI-4.0.5

[blake_oneapi-2021.1.1-openmpi-4.0.5-openmp]
use BLAKE_ONEAPI-2021.1.1-OPENMPI-4.0.5
use BLAKE_OPENMP

[blake_oneapi-2021.1.1-openmpi-4.0.5-serial]
use BLAKE_ONEAPI-2021.1.1-OPENMPI-4.0.5



#------------------------------------------------------------------------------
# machine-type-2
#------------------------------------------------------------------------------

# Partial environments intended to be `use`d within others.

[machine-type-2_PRE]
use MODULE-PURGE
module-use             : /projects/sems/modulefiles/projects
module-load sems-env
module-load sems-git   : 2.10.1
module-load sems-cmake : 3.19.1

[machine-type-2_POST]
module-load sems-ninja_fortran : 1.8.2
envvar-set  BINUTILS_ROOT      : /usr
use OMPI-INTEL-VARS
use MPI-COMPILER-VARS

[machine-type-2_OPENMP]
envvar-set   OMP_NUM_THREADS : 2
envvar-unset OMP_PLACES
envvar-unset OMP_PROC_BIND

[machine-type-2_INTEL-18.0.2-OPENMPI-4.0.1]
use machine-type-2_PRE
module-load    intel             : 18.0.2.199
module-load    mkl               : 18.0.5.274
module-load    openmpi-intel     : 4.0
envvar-prepend PATH              : /usr/tce/packages/gcc/gcc-6.1.0/bin
envvar-prepend LD_LIBRARY_PATH   : /usr/tce/packages/gcc/gcc-6.1.0/lib64
envvar-set     SPARC_TPL_BASE    : /projects/sparc/tpls/machine-type-2-bdw
envvar-set     SPARC_TPL_EXT     : machine-type-2-bdw_intel-19.0.5
envvar-set     SPARC_TPL_MPI_EXT : ${SPARC_TPL_EXT}_openmpi-4.0.1
envvar-set     BOOST_ROOT        : ${SPARC_TPL_BASE}/boost-1.72.0/00000000/${SPARC_TPL_EXT}
envvar-set     HDF5_ROOT         : ${SPARC_TPL_BASE}/hdf5-1.10.5/00000000/${SPARC_TPL_MPI_EXT}
envvar-set     CGNS_ROOT         : ${SPARC_TPL_BASE}/cgns-c09a5cd/d313cc2f822078e47c7dbdee074ecb0431e573eb/${SPARC_TPL_MPI_EXT}
envvar-set     PNETCDF_ROOT      : ${SPARC_TPL_BASE}/pnetcdf-1.12.1/6144dc67b2041e4093063a04e89fc1e33398bd09/${SPARC_TPL_MPI_EXT}
envvar-set     NETCDF_ROOT       : ${SPARC_TPL_BASE}/netcdf-4.7.0/24baa07a3fa1ff9dbc8e70dc591ebbdec56783b2/${SPARC_TPL_MPI_EXT}
envvar-set     PARMETIS_ROOT     : ${SPARC_TPL_BASE}/parmetis-4.0.3/00000000/${SPARC_TPL_MPI_EXT}
envvar-set     METIS_ROOT        : ${PARMETIS_ROOT}
envvar-set     LIBHIO_ROOT       : ${SPARC_TPL_BASE}/libhio-1.4.1.2/00000000/${SPARC_TPL_MPI_EXT}
envvar-set     EUCLID_ROOT       : ${SPARC_TPL_BASE}/euclid-20.23/8b68b12f72b59648c9a0a962a6d55ea978199860/${SPARC_TPL_MPI_EXT}
envvar-set     SGM_ROOT          : ${SPARC_TPL_BASE}/sgm-20.23/00000000/${SPARC_TPL_MPI_EXT}
envvar-set     SUPERLUDIST_ROOT  : ${SPARC_TPL_BASE}/superlu_dist-5.4.0/a3121eaff44f7bf7d44e625c3b3d2a9911e58876/${SPARC_TPL_MPI_EXT}
use COMPILER-VARS
use machine-type-2_POST

[machine-type-2_INTEL-18.0.2-OPENMPI-4.0.3]
use machine-type-2_PRE
module-load              sparc-dev : intel-19.0.4_openmpi-4.0.3
module-swap              intel     : intel/18.0.2.199
envvar-remove-path-entry PATH      : /projects/sparc/tools/vvt
use machine-type-2_POST

[machine-type-2_INTEL-19.0.4-OPENMPI-4.0.3]
use machine-type-2_PRE
module-load sparc-dev : intel-19.0.4_openmpi-4.0.3
use machine-type-2_POST

# Full environments intended to be loaded.

[machine-type-2_intel-18.0.2-openmpi-4.0.1-openmp]
use machine-type-2_INTEL-18.0.2-OPENMPI-4.0.1
use machine-type-2_OPENMP

[machine-type-2_intel-18.0.2-openmpi-4.0.1-serial]
use machine-type-2_INTEL-18.0.2-OPENMPI-4.0.1

[machine-type-2_intel-18.0.2-openmpi-4.0.3-openmp]
use machine-type-2_INTEL-18.0.2-OPENMPI-4.0.3
use machine-type-2_OPENMP

[machine-type-2_intel-18.0.2-openmpi-4.0.3-serial]
use machine-type-2_INTEL-18.0.2-OPENMPI-4.0.3

[machine-type-2_intel-19.0.4-openmpi-4.0.3-openmp]
use machine-type-2_INTEL-19.0.4-OPENMPI-4.0.3
use machine-type-2_OPENMP

[machine-type-2_intel-19.0.4-openmpi-4.0.3-serial]
use machine-type-2_INTEL-19.0.4-OPENMPI-4.0.3



#------------------------------------------------------------------------------
# rhel7
#------------------------------------------------------------------------------

# Partial environments intended to be `use`d within others.

[RHEL7_PRE]
use MODULE-PURGE
module-use                     : /projects/sems/modulefiles/projects
module-load sems-env
module-load sems-cmake         : 3.19.1
module-load sems-ninja_fortran : 1.10.0

[RHEL7_INTEL]
use OMPI-INTEL-VARS
envvar-set-if-empty LDFLAGS : ""
envvar-set          LDFLAGS : ${LDFLAGS} -lifcore

[RHEL7_CEE_INTEL-19.0.3-MPICH2-3.2]
use RHEL7_PRE
module-load sparc-dev : intel-19.0.3_mpich2-3.2
use MPI-COMPILER-VARS
use RHEL7_INTEL

[RHEL7_SEMS]
module-load         sems-openmpi      : 1.10.1
module-load         sems-netcdf       : 4.7.3/parallel
module-load         sems-hdf5         : 1.10.6/parallel
module-load         sems-zlib         : 1.2.8/base
module-load         sems-boost        : 1.59.0/base
module-unload       sems-python
module-load         sems-superlu      : 4.3/base
module-load         sems-git          : 2.10.1
envvar-set          HWLOC_LIBS        : -lhwloc
envvar-set          BOOST_ROOT        : ${SEMS_BOOST_ROOT}
envvar-set          HDF5_ROOT         : ${SEMS_HDF5_ROOT}
envvar-set          NETCDF_ROOT       : ${SEMS_NETCDF_ROOT}
envvar-set-if-empty SEMS_PNETCDF_ROOT : ${SEMS_NETCDF_ROOT}
envvar-set          PNETCDF_ROOT      : ${SEMS_PNETCDF_ROOT}

[RHEL7_SEMS-INTEL]
module-load atdm-env
module-load atdm-mkl        : 18.0.5
envvar-set  LM_LICENSE_FILE : 28518@cee-infra009.sandia.gov

[RHEL7_SEMS-OPENMP]
envvar-set OMP_NUM_THREADS : 2

[RHEL7_SEMS-SERIAL]
envvar-set OMP_PROC_BIND   : false
envvar-set OMP_NUM_THREADS : 1

[RHEL7_SEMS-CLANG-3.9.0-OPENMPI-1.10.1]
use RHEL7_PRE
module-load sems-clang : 3.9.0
use MPI-COMPILER-VARS
use RHEL7_SEMS
use OMPI-CLANG-VARS

[RHEL7_SEMS-CLANG-7.0.1-OPENMPI-1.10.1]
use RHEL7_PRE
module-load sems-clang : 7.0.1
use MPI-COMPILER-VARS
use RHEL7_SEMS
use OMPI-CLANG-VARS

[RHEL7_SEMS-CLANG-10.0.0-OPENMPI-1.10.1]
use RHEL7_PRE
module-load sems-clang : 10.0.0
use MPI-COMPILER-VARS
use RHEL7_SEMS
use OMPI-CLANG-VARS

[RHEL7_SEMS-GNU-7.2.0-OPENMPI-1.10.1]
use RHEL7_PRE
module-load sems-gcc : 7.2.0
use MPI-COMPILER-VARS
use RHEL7_SEMS
use OMPI-GNU-VARS

[RHEL7_SEMS-INTEL-17.0.1-OPENMPI-1.10.1]
use RHEL7_PRE
module-load sems-intel : 17.0.1
use MPI-COMPILER-VARS
use RHEL7_SEMS
use RHEL7_SEMS-INTEL
use RHEL7_INTEL

[RHEL7_SEMS-INTEL-18.0.5-OPENMPI-1.10.1]
use RHEL7_PRE
module-load sems-gcc   : 7.2.0
module-load sems-intel : 18.0.5
use MPI-COMPILER-VARS
use RHEL7_SEMS
use RHEL7_SEMS-INTEL
use RHEL7_INTEL

# Full environments intended to be loaded.

[rhel7_cee-clang-9.0.1-openmpi-4.0.3-serial]
use RHEL7_PRE
module-load sparc-dev : clang-9.0.1_openmpi-4.0.3
use MPI-COMPILER-VARS
use OMPI-CLANG-VARS

[rhel7_cee-cuda-10.1.243-gnu-7.2.0-openmpi-4.0.3]
use RHEL7_PRE
module-load sparc-dev : cuda-10.1.243_gcc-7.2.0_openmpi-4.0.3
use MPI-COMPILER-VARS

[rhel7_cee-gnu-7.2.0-openmpi-4.0.3-serial]
use RHEL7_PRE
module-load  sparc-dev : gcc-7.2.0_openmpi-4.0.3
envvar-unset OMP_NUM_THREADS
envvar-unset OMP_PLACES
envvar-unset OMP_PROC_BIND
use MPI-COMPILER-VARS
use OMPI-GNU-VARS

[rhel7_cee-intel-19.0.3-intelmpi-2018.4-serial]
use RHEL7_PRE
module-load sparc-dev : intel-19.0.3_intelmpi-2018.4
use MPI-COMPILER-VARS
use RHEL7_INTEL

[rhel7_cee-intel-19.0.3-mpich2-3.2-openmp]
use RHEL7_CEE_INTEL-19.0.3-MPICH2-3.2
envvar-set   OMP_NUM_THREADS : 3
envvar-set   OMP_PROC_BIND   : false
envvar-unset OMP_PLACES

[rhel7_cee-intel-19.0.3-mpich2-3.2-serial]
use RHEL7_CEE_INTEL-19.0.3-MPICH2-3.2

[rhel7_sems-clang-3.9.0-openmpi-1.10.1-openmp]
use RHEL7_SEMS-CLANG-3.9.0-OPENMPI-1.10.1
use RHEL7_SEMS-OPENMP

[rhel7_sems-clang-3.9.0-openmpi-1.10.1-serial]
use RHEL7_SEMS-CLANG-3.9.0-OPENMPI-1.10.1
use RHEL7_SEMS-SERIAL

[rhel7_sems-clang-7.0.1-openmpi-1.10.1-openmp]
use RHEL7_SEMS-CLANG-7.0.1-OPENMPI-1.10.1
use RHEL7_SEMS-OPENMP

[rhel7_sems-clang-7.0.1-openmpi-1.10.1-serial]
use RHEL7_SEMS-CLANG-7.0.1-OPENMPI-1.10.1
use RHEL7_SEMS-SERIAL

[rhel7_sems-clang-10.0.0-openmpi-1.10.1-openmp]
use RHEL7_SEMS-CLANG-10.0.0-OPENMPI-1.10.1
use RHEL7_SEMS-OPENMP

[rhel7_sems-clang-10.0.0-openmpi-1.10.1-serial]
use RHEL7_SEMS-CLANG-10.0.0-OPENMPI-1.10.1
use RHEL7_SEMS-SERIAL

[rhel7_sems-cuda-10.1-gnu-7.2.0-openmpi-1.10.1]
use RHEL7_PRE
module-load  sems-gcc                        : 7.2.0
module-load  sems-cuda                       : 10.1
envvar-set   CUDA_LAUNCH_BLOCKING            : 1
envvar-set   CUDA_MANAGED_FORCE_DEVICE_ALLOC : 1
envvar-set   KOKKOS_NUM_DEVICES              : 2
use MPI-COMPILER-VARS
use OMPI-GNU-VARS
envvar-unset OMPI_CXX
use RHEL7_SEMS

[rhel7_sems-gnu-7.2.0-openmpi-1.10.1-openmp]
use RHEL7_SEMS-GNU-7.2.0-OPENMPI-1.10.1
use RHEL7_SEMS-OPENMP

[rhel7_sems-gnu-7.2.0-openmpi-1.10.1-serial]
use RHEL7_SEMS-GNU-7.2.0-OPENMPI-1.10.1
use RHEL7_SEMS-SERIAL

[rhel7_sems-intel-17.0.1-openmpi-1.10.1-openmp]
use RHEL7_SEMS-INTEL-17.0.1-OPENMPI-1.10.1
use RHEL7_SEMS-OPENMP

[rhel7_sems-intel-17.0.1-openmpi-1.10.1-serial]
use RHEL7_SEMS-INTEL-17.0.1-OPENMPI-1.10.1
use RHEL7_SEMS-SERIAL

[rhel7_sems-intel-18.0.5-openmpi-1.10.1-openmp]
use RHEL7_SEMS-INTEL-18.0.5-OPENMPI-1.10.1
use RHEL7_SEMS-OPENMP

[rhel7_sems-intel-18.0.5-openmpi-1.10.1-serial]
use RHEL7_SEMS-INTEL-18.0.5-OPENMPI-1.10.1
use RHEL7_SEMS-SERIAL



#------------------------------------------------------------------------------
# machine-name-1
#------------------------------------------------------------------------------

# Partial environments intended to be `use`d within others.

[machine-name-1_PRE]
use MODULE-PURGE

[machine-name-1_POST]
use MPI-COMPILER-VARS
use OMPI-GNU-VARS
envvar-unset OMPI_CXX

[machine-name-1_CUDA]
envvar-set CUDA_LAUNCH_BLOCKING            : 1
envvar-set CUDA_MANAGED_FORCE_DEVICE_ALLOC : 1
envvar-set KOKKOS_NUM_DEVICES              : 2

[machine-name-1_OPENMP]
envvar-set OMP_NUM_THREADS : 2

[machine-name-1_GNU-7.2.0-OPENMPI-2.1.2]
use machine-name-1_PRE
module-load devpack  : 20180521/openmpi/2.1.2/gcc/7.2.0/cuda/9.2.88
module-swap openblas : netlib/3.8.0/gcc/7.2.0
use machine-name-1_POST
envvar-find-in-path OMPI_CXX : g++

# Full environments intended to be loaded.

[machine-name-1_cuda-9.2-gnu-7.2.0-openmpi-2.1.2]
use machine-name-1_PRE
module-load devpack  : 20180521/openmpi/2.1.2/gcc/7.2.0/cuda/9.2.88
module-swap openblas : netlib/3.8.0/gcc/7.2.0
use machine-name-1_POST
use machine-name-1_CUDA

[machine-name-1_cuda-10.1-gnu-7.2.0-openmpi-4.0.1]
use machine-name-1_PRE
module-load devpack : 20190404/openmpi/4.0.1/gcc/7.2.0/cuda/10.1.105
use machine-name-1_POST
use machine-name-1_CUDA

[machine-name-1_gnu-7.2.0-openmpi-2.1.2-openmp]
use machine-name-1_GNU-7.2.0-OPENMPI-2.1.2
use machine-name-1_OPENMP

[machine-name-1_gnu-7.2.0-openmpi-2.1.2-serial]
use machine-name-1_GNU-7.2.0-OPENMPI-2.1.2



#------------------------------------------------------------------------------
# machine-type-1
#------------------------------------------------------------------------------

# Partial environments intended to be `use`d within others.

[machine-type-1_OPENMP]
envvar-set OMP_NUM_THREADS : 2

[machine-type-1_INTEL-18.0.0-OPENMPI-1.10.5]
use MODULE-PURGE
module-use                       : /projects/sems/modulefiles/projects
module-load   sems-env
module-load   sems-cmake         : 3.19.1
module-load   sems-ninja_fortran : 1.8.2
module-load   sems-intel         : 18.0.0
module-load   sems-openmpi       : 1.10.5
module-load   sems-netcdf        : 4.7.3/parallel
module-load   sems-parmetis      : 4.0.3/64bit_parallel
module-load   sems-scotch        : 6.0.3/nopthread_64bit_parallel
module-load   sems-superlu       : 5.2.1/base
module-load   sems-yaml_cpp      : 0.5.3/base
module-load   sems-zlib          : 1.2.8/base
module-unload sems-boost         : 1.63.0/base
module-load   sems-boost         : 1.66.0/base
module-swap   mkl                : mkl/18.0.5.274
module-load   cde/v1/compiler    : gcc/7.2.0
module-unload sems-python
envvar-set    BOOST_ROOT         : ${SEMS_BOOST_ROOT}
envvar-set    HDF5_ROOT          : ${SEMS_HDF5_ROOT}
envvar-set    NETCDF_ROOT        : ${SEMS_NETCDF_ROOT}
envvar-set    PNETCDF_ROOT       : ${SEMS_NETCDF_ROOT}
envvar-set    YAMLCPP_ROOT       : ${SEMS_YAML_CPP_ROOT}
use COMPILER-VARS
use MPI-COMPILER-VARS
use OMPI-INTEL-VARS

# Full environments intended to be loaded.

[machine-type-1_intel-18.0.0-openmpi-1.10.5-openmp]
use machine-type-1_INTEL-18.0.0-OPENMPI-1.10.5
use machine-type-1_OPENMP

[machine-type-1_intel-18.0.0-openmpi-1.10.5-serial]
use machine-type-1_INTEL-18.0.0-OPENMPI-1.10.5



#------------------------------------------------------------------------------
# machine-type-3
#------------------------------------------------------------------------------

# Partial environments intended to be `use`d within others.

[machine-type-3_PRE]
use MODULE-PURGE

[machine-type-3_POST]
module-load  ninja
module-load  cmake : 3.17.1
envvar-set   MPI_ROOT         : ${MPI_DIR}
envvar-set   BLAS_ROOT        : ${ARMPL_DIR}
envvar-set   HDF5_ROOT        : ${HDF5_DIR}
envvar-set   NETCDF_ROOT      : ${NETCDF_DIR}
envvar-set   PNETCDF_ROOT     : ${PNETCDF_DIR}
envvar-set   ZLIB_ROOT        : ${ZLIB_DIR}
envvar-set   CGNS_ROOT        : ${CGNS_DIR}
envvar-set   BOOST_ROOT       : ${BOOST_DIR}
envvar-set   METIS_ROOT       : ${METIS_DIR}
envvar-set   PARMETIS_ROOT    : ${PARMETIS_DIR}
envvar-set   SUPERLUDIST_ROOT : ${SUPLERLU_DIST_DIR}
envvar-set   BINUTILS_ROOT    : ${BINUTILS_DIR}
envvar-unset HWLOC_LIBS
use COMPILER-VARS
envvar-set   FC               : mpif90
use MPI-COMPILER-VARS

[machine-type-3_OPENMP]
envvar-set OMP_NUM_THREADS : 2

[machine-type-3_SERIAL]
envvar-set OMP_PROC_BIND   : false
envvar-set OMP_NUM_THREADS : 1

[machine-type-3_ARM-20.0-OPENMPI-4.0.2]
use machine-type-3_PRE
module-load   devpack-arm
module-unload yaml-cpp
module-load   python      : 3.6.8-arm
module-load   arm         : 20.0
module-load   openmpi4    : 4.0.2
module-load   armpl       : 20.0.0
module-load   git         : 2.19.2
envvar-set    LAPACK_ROOT : ${ARMPL_DIR}
use machine-type-3_POST

[machine-type-3_ARM-20.1-OPENMPI-4.0.3]
use machine-type-3_PRE
module-load   sparc-dev : arm-20.1_openmpi-4.0.3
module-unload yaml-cpp
use machine-type-3_POST

[machine-type-3_ARM-20.1-OPENMPI-4.0.5]
use machine-type-3_PRE
module-load   sparc-dev : arm-20.1_openmpi-4.0.5
module-unload yaml-cpp
use machine-type-3_POST

# Full environments intended to be loaded.

[machine-type-3_arm-20.0-openmpi-4.0.2-openmp]
use machine-type-3_ARM-20.0-OPENMPI-4.0.2
use machine-type-3_OPENMP

[machine-type-3_arm-20.0-openmpi-4.0.2-serial]
use machine-type-3_ARM-20.0-OPENMPI-4.0.2
use machine-type-3_SERIAL

[machine-type-3_arm-20.1-openmpi-4.0.3-openmp]
use machine-type-3_ARM-20.1-OPENMPI-4.0.3
use machine-type-3_OPENMP
envvar-unset OMP_PLACES
envvar-unset OMP_PROC_BIND

[machine-type-3_arm-20.1-openmpi-4.0.3-serial]
use machine-type-3_ARM-20.1-OPENMPI-4.0.3
use machine-type-3_SERIAL

[machine-type-3_arm-20.1-openmpi-4.0.5-openmp]
use machine-type-3_ARM-20.1-OPENMPI-4.0.5
use machine-type-3_OPENMP
envvar-unset OMP_PLACES
envvar-unset OMP_PROC_BIND

[machine-type-3_arm-20.1-openmpi-4.0.5-serial]
use machine-type-3_ARM-20.1-OPENMPI-4.0.5
use machine-type-3_SERIAL
